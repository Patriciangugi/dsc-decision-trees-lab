{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Building Trees using scikit-learn - Lab\n","\n","## Introduction\n","\n","Following the simple example you saw in the previous lesson, you'll now build a decision tree for a more complex dataset. This lab covers all major areas of standard machine learning practice, from data acquisition to evaluation of results. We'll continue to use the Scikit-learn and Pandas libraries to conduct this analysis, following the same structure we saw in the previous lesson.\n","\n","## Objectives\n","\n","In this lab you will:\n","\n","- Use scikit-learn to fit a decision tree classification model \n","- Use entropy and information gain to identify the best attribute to split on at each node \n","- Plot a decision tree using Python "]},{"cell_type":"markdown","metadata":{},"source":["## UCI Banknote authentication dataset"]},{"cell_type":"markdown","metadata":{},"source":["In this lab, you'll work with a popular dataset for classification called the \"UCI Bank note authentication dataset\". This data was extracted from images that were taken from genuine and forged banknotes! The notes were first digitized, followed by a numerical transformation using DSP techniques. The final set of engineered features are all continuous in nature, meaning that our dataset consists entirely of floats, with no strings to worry about. If you're curious about how the dataset was created, you can visit the UCI link [here](https://archive.ics.uci.edu/ml/datasets/banknote+authentication)!\n","\n","We have the following attributes in the dataset:  \n","\n","1. __Variance__ of wavelet transformed image (continuous) \n","2. __Skewness__ of wavelet transformed image (continuous) \n","3. __Curtosis__ of wavelet transformed image (continuous) \n","4. __Entropy__ of image (continuous) \n","5. __Class__ (integer) - Target/Label "]},{"cell_type":"markdown","metadata":{},"source":["## Step 1: Import the necessary libraries \n","\n","We've imported all the necessary modules you will require for this lab, go ahead and run the following cell: "]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# Import necessary libraries\n","import numpy as np \n","import pandas as pd \n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split\n","from sklearn.tree import DecisionTreeClassifier \n","from sklearn.metrics import accuracy_score, roc_curve, auc\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn import tree"]},{"cell_type":"markdown","metadata":{},"source":["## Step 2: Import data\n","\n","Now, you'll load our dataset in a DataFrame, perform some basic EDA, and get a general feel for the data you'll be working with.\n","\n","- Import the file `'data_banknote_authentication.csv'` as a pandas DataFrame. Note that there is no header information in this dataset \n","- Assign column names `'Variance'`, `'Skewness'`, `'Kurtosis'`, `'Entropy'`, and `'Class'` to the dataset in the given order \n","- View the basic statistics and shape of the dataset \n","- Check for the frequency of positive and negative examples in the target variable"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# Create DataFrame\n","df = pd.read_csv('https://raw.githubusercontent.com/Patriciangugi/dsc-decision-trees-lab/master/data_banknote_authentication.csv', header=None)\n","\n","df.columns = ['Variance', 'Skewness', 'Kurtosis', 'Entropy', 'Class']"]},{"cell_type":"markdown","metadata":{},"source":["# Describe the dataset\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["          Variance     Skewness     Kurtosis      Entropy        Class\n","count  1372.000000  1372.000000  1372.000000  1372.000000  1372.000000\n","mean      0.433735     1.922353     1.397627    -1.191657     0.444606\n","std       2.842763     5.869047     4.310030     2.101013     0.497103\n","min      -7.042100   -13.773100    -5.286100    -8.548200     0.000000\n","25%      -1.773000    -1.708200    -1.574975    -2.413450     0.000000\n","50%       0.496180     2.319650     0.616630    -0.586650     0.000000\n","75%       2.821475     6.814625     3.179250     0.394810     1.000000\n","max       6.824800    12.951600    17.927400     2.449500     1.000000\n","Shape of the dataset: (1372, 5)\n"]}],"source":["# Shape of dataset\n","print(df.describe())\n","\n","# Display the shape of the dataset\n","print(f\"Shape of the dataset: {df.shape}\")"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Class Distribution:\n","Class\n","0    762\n","1    610\n","Name: count, dtype: int64\n"]}],"source":["# Class frequency of target variable \n","class_distribution = df['Class'].value_counts()\n","print(f\"Class Distribution:\\n{class_distribution}\")"]},{"cell_type":"markdown","metadata":{},"source":["## Step 3: Create features, labels, training, and test data\n","\n","Now we need to create our feature set `X` and labels `y`:  \n","- Create `X` and `y` by selecting the appropriate columns from the dataset\n","- Create a 80/20 split on the dataset for training/test. Use `random_state=10` for reproducibility"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training features shape: (1097, 4)\n","Testing features shape: (275, 4)\n","Training labels shape: (1097,)\n","Testing labels shape: (275,)\n"]}],"source":["# Create features and labels\n","# Create features and labels\n","X = df[['Variance', 'Skewness', 'Kurtosis', 'Entropy']].values\n","y = df['Class'].values\n","\n","# Create a train/test split with 80/20 ratio\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n","\n","# Verify the shapes of the resulting datasets\n","print(\"Training features shape:\", X_train.shape)\n","print(\"Testing features shape:\", X_test.shape)\n","print(\"Training labels shape:\", y_train.shape)\n","print(\"Testing labels shape:\", y_test.shape)\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Training features shape: (1097, 4)\n","Testing features shape: (275, 4)\n","Training labels shape: (1097,)\n","Testing labels shape: (275,)\n"]}],"source":["# Perform an 80/20 split\n","from sklearn.model_selection import train_test_split\n","\n","# Create features and labels\n","X = df[['Variance', 'Skewness', 'Kurtosis', 'Entropy']].values\n","y = df['Class'].values\n","\n","# Perform the train/test split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n","\n","# Verify the shapes of the resulting datasets\n","print(\"Training features shape:\", X_train.shape)\n","print(\"Testing features shape:\", X_test.shape)\n","print(\"Training labels shape:\", y_train.shape)\n","print(\"Testing labels shape:\", y_test.shape)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Step 4: Train the classifier and make predictions\n","- Create an instance of a decision tree classifier with `random_state=10` for reproducibility\n","- Fit the training data to the model \n","- Use the trained model to make predictions with test data"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Predictions: [0 0 1 0 1 1 1 0 0 0 1 1 1 0 1 1 0 0 1 0 0 0 1 0 1 1 1 1 1 0 1 0 0 1 0 0 0\n"," 1 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 1 0 0 1 1 0 1 0 1 0 0 0 0 0 0 1 0 1 1 0\n"," 1 0 0 0 1 1 1 0 1 0 0 1 0 0 0 1 1 0 1 0 1 0 1 1 0 0 0 1 1 1 0 1 0 0 0 0 0\n"," 1 1 0 1 1 0 0 1 1 0 0 1 0 1 1 0 1 1 0 0 0 0 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0\n"," 1 0 1 0 0 1 0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 0 0 1 1 1 0 1 1 0 0 0 1 0 1 1 1\n"," 1 1 0 1 0 0 1 1 1 0 0 0 0 0 1 1 0 0 1 1 0 0 0 1 0 0 0 1 1 1 1 1 0 1 1 1 0\n"," 1 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 1 1 1 0 1\n"," 0 0 0 0 0 1 1 1 0 1 0 0 0 1 0 0]\n"]}],"source":["# Train a DT classifier\n","from sklearn.tree import DecisionTreeClassifier\n","\n","# Create an instance of the Decision Tree Classifier\n","clf = DecisionTreeClassifier(random_state=10)\n","\n","# Fit the model on the training data\n","clf.fit(X_train, y_train)\n","\n","# Make predictions on the test data\n","y_pred = clf.predict(X_test)\n","\n","# Print some details about the predictions\n","print(\"Predictions:\", y_pred)\n","\n"]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy: 0.9781818181818182\n","Confusion Matrix:\n"," [[149   3]\n"," [  3 120]]\n","Classification Report:\n","               precision    recall  f1-score   support\n","\n","           0       0.98      0.98      0.98       152\n","           1       0.98      0.98      0.98       123\n","\n","    accuracy                           0.98       275\n","   macro avg       0.98      0.98      0.98       275\n","weighted avg       0.98      0.98      0.98       275\n","\n"]}],"source":["# Make predictions for test data\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n","\n","# Calculate accuracy\n","accuracy = accuracy_score(y_test, y_pred)\n","print(\"Accuracy:\", accuracy)\n","\n","# Calculate confusion matrix\n","conf_matrix = confusion_matrix(y_test, y_pred)\n","print(\"Confusion Matrix:\\n\", conf_matrix)\n","\n","# Print classification report\n","class_report = classification_report(y_test, y_pred)\n","print(\"Classification Report:\\n\", class_report)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["## Step 5: Check predictive performance\n","\n","Use different evaluation measures to check the predictive performance of the classifier: \n","- Check the accuracy, AUC, and create a confusion matrix \n","- Interpret the results "]},{"cell_type":"code","execution_count":10,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Accuracy is :0.9781818181818182\n","\n","AUC is :0.98\n","\n","Confusion Matrix\n","----------------\n"]}],"source":["from sklearn.metrics import accuracy_score, roc_curve, auc, confusion_matrix\n","# Calculate accuracy \n","acc = accuracy_score(y_test, y_pred)\n","print('Accuracy is :{0}'.format(acc))\n","\n","# Check the AUC for predictions\n","false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred)\n","roc_auc = auc(false_positive_rate, true_positive_rate)\n","print('\\nAUC is :{0}'.format(round(roc_auc, 2)))\n","\n","# Create and print a confusion matrix \n","print('\\nConfusion Matrix')\n","print('----------------')"]},{"cell_type":"markdown","metadata":{},"source":["## Level up (Optional)\n","\n","\n","### Re-grow the tree using entropy "]},{"cell_type":"markdown","metadata":{},"source":["The default impurity criterion in scikit-learn is the Gini impurity. We can change it to entropy by passing in the argument `criterion='entropy'` to the classifier in the training phase.  \n","\n","- Create an instance of a decision tree classifier with `random_state=10` for reproducibility. Make sure you use entropy to calculate impurity \n","- Fit this classifier to the training data \n","- Run the given code to plot the decision tree"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[{"data":{"text/html":["<style>#sk-container-id-2 {\n","  /* Definition of color scheme common for light and dark mode */\n","  --sklearn-color-text: black;\n","  --sklearn-color-line: gray;\n","  /* Definition of color scheme for unfitted estimators */\n","  --sklearn-color-unfitted-level-0: #fff5e6;\n","  --sklearn-color-unfitted-level-1: #f6e4d2;\n","  --sklearn-color-unfitted-level-2: #ffe0b3;\n","  --sklearn-color-unfitted-level-3: chocolate;\n","  /* Definition of color scheme for fitted estimators */\n","  --sklearn-color-fitted-level-0: #f0f8ff;\n","  --sklearn-color-fitted-level-1: #d4ebff;\n","  --sklearn-color-fitted-level-2: #b3dbfd;\n","  --sklearn-color-fitted-level-3: cornflowerblue;\n","\n","  /* Specific color for light theme */\n","  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n","  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n","  --sklearn-color-icon: #696969;\n","\n","  @media (prefers-color-scheme: dark) {\n","    /* Redefinition of color scheme for dark theme */\n","    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n","    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n","    --sklearn-color-icon: #878787;\n","  }\n","}\n","\n","#sk-container-id-2 {\n","  color: var(--sklearn-color-text);\n","}\n","\n","#sk-container-id-2 pre {\n","  padding: 0;\n","}\n","\n","#sk-container-id-2 input.sk-hidden--visually {\n","  border: 0;\n","  clip: rect(1px 1px 1px 1px);\n","  clip: rect(1px, 1px, 1px, 1px);\n","  height: 1px;\n","  margin: -1px;\n","  overflow: hidden;\n","  padding: 0;\n","  position: absolute;\n","  width: 1px;\n","}\n","\n","#sk-container-id-2 div.sk-dashed-wrapped {\n","  border: 1px dashed var(--sklearn-color-line);\n","  margin: 0 0.4em 0.5em 0.4em;\n","  box-sizing: border-box;\n","  padding-bottom: 0.4em;\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","#sk-container-id-2 div.sk-container {\n","  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n","     but bootstrap.min.css set `[hidden] { display: none !important; }`\n","     so we also need the `!important` here to be able to override the\n","     default hidden behavior on the sphinx rendered scikit-learn.org.\n","     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n","  display: inline-block !important;\n","  position: relative;\n","}\n","\n","#sk-container-id-2 div.sk-text-repr-fallback {\n","  display: none;\n","}\n","\n","div.sk-parallel-item,\n","div.sk-serial,\n","div.sk-item {\n","  /* draw centered vertical line to link estimators */\n","  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n","  background-size: 2px 100%;\n","  background-repeat: no-repeat;\n","  background-position: center center;\n","}\n","\n","/* Parallel-specific style estimator block */\n","\n","#sk-container-id-2 div.sk-parallel-item::after {\n","  content: \"\";\n","  width: 100%;\n","  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n","  flex-grow: 1;\n","}\n","\n","#sk-container-id-2 div.sk-parallel {\n","  display: flex;\n","  align-items: stretch;\n","  justify-content: center;\n","  background-color: var(--sklearn-color-background);\n","  position: relative;\n","}\n","\n","#sk-container-id-2 div.sk-parallel-item {\n","  display: flex;\n","  flex-direction: column;\n","}\n","\n","#sk-container-id-2 div.sk-parallel-item:first-child::after {\n","  align-self: flex-end;\n","  width: 50%;\n","}\n","\n","#sk-container-id-2 div.sk-parallel-item:last-child::after {\n","  align-self: flex-start;\n","  width: 50%;\n","}\n","\n","#sk-container-id-2 div.sk-parallel-item:only-child::after {\n","  width: 0;\n","}\n","\n","/* Serial-specific style estimator block */\n","\n","#sk-container-id-2 div.sk-serial {\n","  display: flex;\n","  flex-direction: column;\n","  align-items: center;\n","  background-color: var(--sklearn-color-background);\n","  padding-right: 1em;\n","  padding-left: 1em;\n","}\n","\n","\n","/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n","clickable and can be expanded/collapsed.\n","- Pipeline and ColumnTransformer use this feature and define the default style\n","- Estimators will overwrite some part of the style using the `sk-estimator` class\n","*/\n","\n","/* Pipeline and ColumnTransformer style (default) */\n","\n","#sk-container-id-2 div.sk-toggleable {\n","  /* Default theme specific background. It is overwritten whether we have a\n","  specific estimator or a Pipeline/ColumnTransformer */\n","  background-color: var(--sklearn-color-background);\n","}\n","\n","/* Toggleable label */\n","#sk-container-id-2 label.sk-toggleable__label {\n","  cursor: pointer;\n","  display: block;\n","  width: 100%;\n","  margin-bottom: 0;\n","  padding: 0.5em;\n","  box-sizing: border-box;\n","  text-align: center;\n","}\n","\n","#sk-container-id-2 label.sk-toggleable__label-arrow:before {\n","  /* Arrow on the left of the label */\n","  content: \"▸\";\n","  float: left;\n","  margin-right: 0.25em;\n","  color: var(--sklearn-color-icon);\n","}\n","\n","#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {\n","  color: var(--sklearn-color-text);\n","}\n","\n","/* Toggleable content - dropdown */\n","\n","#sk-container-id-2 div.sk-toggleable__content {\n","  max-height: 0;\n","  max-width: 0;\n","  overflow: hidden;\n","  text-align: left;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-2 div.sk-toggleable__content.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-2 div.sk-toggleable__content pre {\n","  margin: 0.2em;\n","  border-radius: 0.25em;\n","  color: var(--sklearn-color-text);\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-2 div.sk-toggleable__content.fitted pre {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n","  /* Expand drop-down */\n","  max-height: 200px;\n","  max-width: 100%;\n","  overflow: auto;\n","}\n","\n","#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n","  content: \"▾\";\n","}\n","\n","/* Pipeline/ColumnTransformer-specific style */\n","\n","#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator-specific style */\n","\n","/* Colorize estimator box */\n","#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","#sk-container-id-2 div.sk-label label.sk-toggleable__label,\n","#sk-container-id-2 div.sk-label label {\n","  /* The background is the default theme color */\n","  color: var(--sklearn-color-text-on-default-background);\n","}\n","\n","/* On hover, darken the color of the background */\n","#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","/* Label box, darken color on hover, fitted */\n","#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n","  color: var(--sklearn-color-text);\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Estimator label */\n","\n","#sk-container-id-2 div.sk-label label {\n","  font-family: monospace;\n","  font-weight: bold;\n","  display: inline-block;\n","  line-height: 1.2em;\n","}\n","\n","#sk-container-id-2 div.sk-label-container {\n","  text-align: center;\n","}\n","\n","/* Estimator-specific */\n","#sk-container-id-2 div.sk-estimator {\n","  font-family: monospace;\n","  border: 1px dotted var(--sklearn-color-border-box);\n","  border-radius: 0.25em;\n","  box-sizing: border-box;\n","  margin-bottom: 0.5em;\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-0);\n","}\n","\n","#sk-container-id-2 div.sk-estimator.fitted {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-0);\n","}\n","\n","/* on hover */\n","#sk-container-id-2 div.sk-estimator:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-2);\n","}\n","\n","#sk-container-id-2 div.sk-estimator.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-2);\n","}\n","\n","/* Specification for estimator info (e.g. \"i\" and \"?\") */\n","\n","/* Common style for \"i\" and \"?\" */\n","\n",".sk-estimator-doc-link,\n","a:link.sk-estimator-doc-link,\n","a:visited.sk-estimator-doc-link {\n","  float: right;\n","  font-size: smaller;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1em;\n","  height: 1em;\n","  width: 1em;\n","  text-decoration: none !important;\n","  margin-left: 1ex;\n","  /* unfitted */\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-unfitted-level-1);\n","}\n","\n",".sk-estimator-doc-link.fitted,\n","a:link.sk-estimator-doc-link.fitted,\n","a:visited.sk-estimator-doc-link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",".sk-estimator-doc-link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover,\n","div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",".sk-estimator-doc-link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","/* Span, style for the box shown on hovering the info icon */\n",".sk-estimator-doc-link span {\n","  display: none;\n","  z-index: 9999;\n","  position: relative;\n","  font-weight: normal;\n","  right: .2ex;\n","  padding: .5ex;\n","  margin: .5ex;\n","  width: min-content;\n","  min-width: 20ex;\n","  max-width: 50ex;\n","  color: var(--sklearn-color-text);\n","  box-shadow: 2pt 2pt 4pt #999;\n","  /* unfitted */\n","  background: var(--sklearn-color-unfitted-level-0);\n","  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n","}\n","\n",".sk-estimator-doc-link.fitted span {\n","  /* fitted */\n","  background: var(--sklearn-color-fitted-level-0);\n","  border: var(--sklearn-color-fitted-level-3);\n","}\n","\n",".sk-estimator-doc-link:hover span {\n","  display: block;\n","}\n","\n","/* \"?\"-specific style due to the `<a>` HTML tag */\n","\n","#sk-container-id-2 a.estimator_doc_link {\n","  float: right;\n","  font-size: 1rem;\n","  line-height: 1em;\n","  font-family: monospace;\n","  background-color: var(--sklearn-color-background);\n","  border-radius: 1rem;\n","  height: 1rem;\n","  width: 1rem;\n","  text-decoration: none;\n","  /* unfitted */\n","  color: var(--sklearn-color-unfitted-level-1);\n","  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n","}\n","\n","#sk-container-id-2 a.estimator_doc_link.fitted {\n","  /* fitted */\n","  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n","  color: var(--sklearn-color-fitted-level-1);\n","}\n","\n","/* On hover */\n","#sk-container-id-2 a.estimator_doc_link:hover {\n","  /* unfitted */\n","  background-color: var(--sklearn-color-unfitted-level-3);\n","  color: var(--sklearn-color-background);\n","  text-decoration: none;\n","}\n","\n","#sk-container-id-2 a.estimator_doc_link.fitted:hover {\n","  /* fitted */\n","  background-color: var(--sklearn-color-fitted-level-3);\n","}\n","</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, random_state=10)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, random_state=10)</pre></div> </div></div></div></div>"],"text/plain":["DecisionTreeClassifier(criterion='entropy', random_state=10)"]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["from sklearn.tree import DecisionTreeClassifier\n","from sklearn import tree\n","import matplotlib.pyplot as plt\n","\n","# Instantiate and fit a DecisionTreeClassifier\n","classifier_2 = DecisionTreeClassifier(random_state=10, criterion='entropy')\n","\n","classifier_2.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"ename":"AttributeError","evalue":"'numpy.ndarray' object has no attribute 'columns'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[1;32mIn[15], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Plot and show decision tree\u001b[39;00m\n\u001b[0;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m20\u001b[39m,\u001b[38;5;241m10\u001b[39m))\n\u001b[1;32m----> 3\u001b[0m tree\u001b[38;5;241m.\u001b[39mplot_tree(classifier_2, feature_names\u001b[38;5;241m=\u001b[39m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m, class_names\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNegative\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPositive\u001b[39m\u001b[38;5;124m'\u001b[39m], filled\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39mtitle(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDecision Tree using Entropy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n","\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'columns'"]},{"data":{"text/plain":["<Figure size 2000x1000 with 0 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["# Plot and show decision tree\n","plt.figure(figsize=(12,12), dpi=500)\n","tree.plot_tree(classifier_2, \n","               feature_names=X.columns,\n","               class_names=np.unique(y).astype('str'),\n","               filled=True, rounded=True)\n","plt.show()"]},{"cell_type":"markdown","metadata":{},"source":["- We discussed earlier that decision trees are very sensitive to outliers. Try to identify and remove/fix any possible outliers in the dataset."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["- Check the distributions of the data. Is there any room for normalization/scaling of the data? Apply these techniques and see if it improves the accuracy score."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["## Summary \n","\n","In this lesson, we looked at growing a decision tree for the banknote authentication dataset, which is composed of extracted continuous features from photographic data. We looked at data acquisition, training, prediction, and evaluation. We also looked at growing trees using entropy vs. gini impurity criteria. In following lessons, we shall look at more pre-training tuning techniques for ensuring an optimal classifier for learning and prediction.  "]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":2}
